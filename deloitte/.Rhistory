xgb <- xgboost(data = data.matrix(X[,-1]),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 12,
nthread = 3
)
library(xgboost)
setwd("C:\\Deloitte\\Kaggle\\deloitte\\")
train <- read.csv("train_round.csv")
test <- read.csv("test_round.csv")
xgb <- xgboost(data = data.matrix(X[,-1]),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 12,
nthread = 3
)
trainp[,-1]
train[,-1]
columns(train)
train.shape()
train.shape
dim(train)
dim(train[,-1])
colnames(train)
colnames(train[,-1])
library(xgboost)
setwd("C:\\Deloitte\\Kaggle\\deloitte\\")
train <- read.csv("train_round.csv")
test <- read.csv("test_round.csv")
colnames(train)
train$YPLL.Rate
y <- train$YPLL.Rate
y
drops <- c('source','FIPS','YPLL.Rate')
drops
train <- train[ , !(names(train) %in% drops)]
colnames(train)
test <- read.csv("test_round.csv")
drops <- c('source','FIPS')
test <- test[ , !(names(test) %in% drops)]
colnames(test)
test <- read.csv("test_round.csv")
test <- test[ , !(names(test) %in% drops)]
colnames(test)
drops <- c('source','FIPS','YPLL.Rate')
test <- read.csv("test_round.csv")
test <- test[ , !(names(test) %in% drops)]
colnames(test)
colnames(train)
xgb <- xgboost(data = data.matrix(train),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 12,
nthread = 3
)
y
xgb <- xgboost(data = data.matrix(train),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "rmse",
objective = "reg:linear",
num_class = 12,
nthread = 3
)
dim(train)
dim(y)
y
dim(y)
typeof(y)
typeof(train)
xgb <- xgboost(data = data.matrix(train),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "rmse",
objective = "reg:linear",
num_class = 12,
nthread = 3
)
xgboost(data = train, booster = "gbtree", objective = "binary:logistic", max.depth = 5, eta = 0.5, nthread = 2, nround = 2,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
xgboost(data = data.matrix(train), booster = "gbtree", objective = "binary:logistic", max.depth = 5, eta = 0.5, nthread = 2, nround = 2,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
xgboost(data = data.matrix(train), booster = "gbtree",label = y, objective = "binary:logistic", max.depth = 5, eta = 0.5, nthread = 2, nround = 2,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
xgboost(data = data.matrix(train), booster = "gbtree",label = y, objective = "reg:linear", max.depth = 5, eta = 0.5, nthread = 2, nround = 2,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
y_pred <- predict(xgb, data.matrix(test)
)
xgb<-xgboost(data = data.matrix(train), booster = "gbtree",label = y, objective = "reg:linear", max.depth = 5, eta = 0.5, nthread = 2, nround = 2,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
xgb<-xgboost(data = data.matrix(train), booster = "gbtree",label = y, objective = "reg:linear", max.depth = 5, eta = 0.5, nthread = 2, nround = 20,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
xgb<-xgboost(data = data.matrix(train), booster = "gbtree",label = y, objective = "reg:linear", max.depth = 5, eta = 0.5, nthread = 2, nround = 200,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
y_pred <- predict(xgb, data.matrix(test))
y_pred
test <- read.csv("test_round.csv")
sample_submission=data.frame("ID"=test$ID,"Predicted"=y_pred)
write.csv(sample_submission,"Sample_submission.csv",row.names=F)
test$ID
test
test<-read.csv("Test.csv")
test$ID
sample_submission=data.frame("ID"=test$ID,"Predicted"=y_pred)
write.csv(sample_submission,"Sample_submission.csv",row.names=F)
sample_submission
y_pred
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree"
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
num_class = 12,
nthread = 3
)
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree"
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
num_class = 12,
nthread = 3
)
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree"
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
objective = "reg:linear",
num_class = 12,
nthread = 3
)
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
num_class = 12,
nthread = 3
)
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
#seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
#num_class = 12,
nthread = 3
)
y_pred <- predict(xgb, data.matrix(test))
test<-read.csv("Test.csv")
sample_submission=data.frame("ID"=test$ID,"Predicted"=y_pred)
write.csv(sample_submission,"Sample_submission.csv",row.names=F)
library(xgboost)
setwd("C:\\Deloitte\\Kaggle\\deloitte\\")
train <- read.csv("train_round.csv")
y <- train$YPLL.Rate
drops <- c('source','FIPS','YPLL.Rate')
train <- train[ , !(names(train) %in% drops)]
test <- read.csv("test_round.csv")
test <- test[ , !(names(test) %in% drops)]
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
#seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
#num_class = 12,
nthread = 3
)
y_pred <- predict(xgb, data.matrix(test))
test1<-read.csv("Test.csv")
sample_submission=data.frame("ID"=test1$ID,"Predicted"=y_pred)
write.csv(sample_submission,"Sample_submission.csv",row.names=F)
sample_submission
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.1,
max_depth = 15,
nround=2500,
subsample = 0.5,
colsample_bytree = 0.5,
#seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
#num_class = 12,
nthread = 3
)
y_pred <- predict(xgb, data.matrix(test))
test1<-read.csv("Test.csv")
sample_submission=data.frame("ID"=test1$ID,"Predicted"=y_pred)
write.csv(sample_submission,"Sample_submission.csv",row.names=F)
sample_submission
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.1,
max_depth = 15,
nround=5000,
subsample = 0.5,
colsample_bytree = 0.5,
#seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
#num_class = 12,
nthread = 3
)
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.05,
max_depth = 20,
nround=5000,
subsample = 0.5,
colsample_bytree = 0.5,
#seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
#num_class = 12,
nthread = 3
)
xgb <- xgboost(data = data.matrix(train),
booster = "gbtree",
label = y,
eta = 0.5,
max_depth = 20,
nround=5000,
subsample = 0.5,
colsample_bytree = 0.5,
#seed = 1,
#eval_metric = "rmse",
objective = "reg:linear",
#num_class = 12,
nthread = 3
)
#xgb<-xgboost(data = data.matrix(train), booster = "gbtree",label = y, objective = "reg:linear", max.depth = 5, eta = 0.5, nthread = 2, nround = 200,  min_child_weight = 1, subsample = 0.5, colsample_bytree = 1,num_parallel_tree = 1)
y_pred <- predict(xgb, data.matrix(test))
test1<-read.csv("Test.csv")
sample_submission=data.frame("ID"=test1$ID,"Predicted"=y_pred)
write.csv(sample_submission,"Sample_submission.csv",row.names=F)
?xgboost
